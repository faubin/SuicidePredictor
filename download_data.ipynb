{
 "metadata": {
  "name": "",
  "signature": "sha256:e78f4e0c8120514e57b0117c3597480b445df05b2359823b4717178f0c8b14f8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Downloading Databases"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This ipython notebook downloads data. One file per state containing health, behavioral, and environmental dataper year is downloaded from www.countyhealthrankings.org to the folder \"downloads\". The script also downloads the suicide rate from www.cdc.gov.\n",
      "\n",
      "The data from County Health Ranking is tricky to download. The file name tend to be slightly different from year to year and state to state. The name of the files are not available on the webpages where they are linked. This code therefore uses a \"guessing\" approach which is highly inneficient. A sleeping command is executed in-between every download to avoid being blacklisted by the website. Reduce this time at your own risk. It may take several hours to download all files with the name \"guessing\" and the default 3 s wait time. To do:\n",
      "- allow to download the files from a \"know file\" list (this list is ont he repository already)\n",
      "- optimize the download process to reduce the \"guessing\"\n",
      "\n",
      "Francois Aubin francois.y.aubin@gmail.com\n",
      "\n",
      "Optimized for Python 2.7 on Ubuntu 16.04\n",
      "\n",
      "Last update in July 2018"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Some Functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import time\n",
      "import requests\n",
      "import pycurl\n",
      "\n",
      "\n",
      "def create_data_structure():\n",
      "    \"\"\"\n",
      "    ensure a downloads folder exist and returns the list of files in it\n",
      "    \"\"\"\n",
      "    if 'downloads' not in os.listdir('.'):\n",
      "        os.mkdir('downloads')\n",
      "        file_list = []\n",
      "    else:\n",
      "        file_list = os.listdir('downloads')\n",
      "    return file_list\n",
      "\n",
      "\n",
      "def clear_data_structure():\n",
      "    \"\"\"\n",
      "    erase the downloads folder to start fresh\n",
      "    \"\"\"\n",
      "    if 'downloads' in os.listdir('.'):\n",
      "        os.system('rm -r downloads')\n",
      "    return\n",
      "\n",
      "\n",
      "def guess_names(file_name):\n",
      "    \"\"\"\n",
      "    return a list of potential file names to download\n",
      "    \"\"\"\n",
      "    name = file_name[:-9]\n",
      "\n",
      "    possible_names = []\n",
      "    # for v in range(9, 0, -1):\n",
      "    for v in range(6, 0, -1):\n",
      "        for ext in ['', '_0', '_1']:\n",
      "            for pre in ['%20', '']:\n",
      "                for rank in ['Rankings', 'Ranking']:\n",
      "                    new_name = '{0:s}{1:s}v{2:d}{3:s}.xls'.format(name, pre, v,\n",
      "                                                                  ext)\n",
      "                    if not rank == 'Rankings':\n",
      "                        new_name = new_name.replace('Rankings', rank)\n",
      "                    possible_names.append(new_name)\n",
      "    return possible_names\n",
      "\n",
      "\n",
      "def download_file(base_url, file_name, save_file_name, file_size_lowerlim=0,\n",
      "                  sleep_time=3):\n",
      "    \"\"\"\n",
      "    download a file, save it as save_file_name, erase it if it is smaller than\n",
      "    file_size_lower_limit (in Bytes)\n",
      "    \"\"\"\n",
      "    url = os.path.join(base_url, file_name)\n",
      "    print(file_name)\n",
      "    print('Downloading {0:s}'.format(save_file_name))\n",
      "\n",
      "    file_ = open(os.path.join('downloads', save_file_name), 'wb')\n",
      "    curl = pycurl.Curl()\n",
      "    curl.setopt(pycurl.URL, url)\n",
      "    curl.setopt(pycurl.FOLLOWLOCATION, 1)\n",
      "    curl.setopt(pycurl.MAXREDIRS, 5)\n",
      "    curl.setopt(pycurl.CONNECTTIMEOUT, 30)\n",
      "    curl.setopt(pycurl.TIMEOUT, 300)\n",
      "    curl.setopt(pycurl.NOSIGNAL, 1)\n",
      "    curl.setopt(pycurl.WRITEDATA, file_)\n",
      "    curl.perform()\n",
      "    file_.close()\n",
      "    time.sleep(sleep_time)\n",
      "\n",
      "    file_size = os.path.getsize(os.path.join('downloads', save_file_name))\n",
      "    if file_size < file_size_lowerlim:\n",
      "        print('File size is {0:d} B'.format(file_size))\n",
      "        os.system(\"rm downloads/{0:s}\".format(save_file_name.replace(' ',\n",
      "                                                                     '/ ')))\n",
      "        return False\n",
      "    else:\n",
      "        f = open(\"downloaded.txt\", 'a')\n",
      "        f.write(file_name + '\\n')\n",
      "        f.close()\n",
      "        return True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "The Script"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sleep_time = 0.1  # s, 3 s will not get you blacklisted, but it will take hours (< 3s not tested)\n",
      "downloaded_files = create_data_structure()\n",
      "\n",
      "# suicide data\n",
      "for year in [2005, 2014, 2015, 2016]:\n",
      "    base_url = 'https://www.cdc.gov/nchs/pressroom/sosmap/suicide-mortality/'\n",
      "    url_file_name = 'SUICIDE{0:d}.csv'.format(year)\n",
      "    if url_file_name not in downloaded_files:\n",
      "        success = download_file(base_url, url_file_name, url_file_name,\n",
      "                                file_size_lowerlim=1000,\n",
      "                                sleep_time=sleep_time)\n",
      "        if not success:\n",
      "            exit(\"Error downloading suicide data\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# health, behavioral, and environmental data\n",
      "base_url = os.path.join(\"http://www.countyhealthrankings.org\", \"sites\",\n",
      "                        \"default\", \"files\", \"state\", \"downloads\")\n",
      "years = range(2010, 2019)\n",
      "states = ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado',\n",
      "          'Connecticut', 'Delaware', 'District of Columbia', 'Florida',\n",
      "          'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa',\n",
      "          'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland',\n",
      "          'Massachusetts', 'Michigan', 'Minnesota', 'Missouri', 'Montana',\n",
      "          'Nebraska', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
      "          'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon',\n",
      "          'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota',\n",
      "          'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
      "          'West Virginia', 'Wisconsin', 'Wyoming']\n",
      "for state in states:\n",
      "    for year in years:\n",
      "        print state, year\n",
      "        file_name = \"{0:d}%20County%20Health%20Rankings\".format(year)\n",
      "        url_state = state.replace(' ',   '%20')\n",
      "        file_name += \"%20{0:s}%20Data%20-%20v1.xls\".format(url_state)\n",
      "\n",
      "        save_file_name = '{0:s}_{1:d}.xls'.format(state, year)\n",
      "\n",
      "        if save_file_name not in downloaded_files:\n",
      "            print '---'\n",
      "            possible_url_file_names = guess_names(file_name)\n",
      "            for url_file_name in possible_url_file_names:\n",
      "                success = download_file(base_url, url_file_name,\n",
      "                                        save_file_name,\n",
      "                                        file_size_lowerlim=29000,\n",
      "                                        sleep_time=sleep_time)\n",
      "                if success:\n",
      "                    break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}